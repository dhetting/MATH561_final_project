{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>range</th>\n",
       "      <th>sum</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>mra_D1_min</th>\n",
       "      <th>...</th>\n",
       "      <th>var_sill</th>\n",
       "      <th>var_range</th>\n",
       "      <th>var_kappa</th>\n",
       "      <th>g</th>\n",
       "      <th>zeros</th>\n",
       "      <th>num_peaks</th>\n",
       "      <th>gradient_max</th>\n",
       "      <th>gradient_min</th>\n",
       "      <th>gradient_mean</th>\n",
       "      <th>gradient_stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>med</td>\n",
       "      <td>-0.197098</td>\n",
       "      <td>-0.230893</td>\n",
       "      <td>-0.210207</td>\n",
       "      <td>-0.214613</td>\n",
       "      <td>-0.206882</td>\n",
       "      <td>-0.210207</td>\n",
       "      <td>-1.198409</td>\n",
       "      <td>0.188957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037780</td>\n",
       "      <td>-0.047950</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.830924</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.228128</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253649</td>\n",
       "      <td>-0.230840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>693</td>\n",
       "      <td>low</td>\n",
       "      <td>3.324597</td>\n",
       "      <td>4.796719</td>\n",
       "      <td>4.874356</td>\n",
       "      <td>5.627270</td>\n",
       "      <td>5.579711</td>\n",
       "      <td>4.874356</td>\n",
       "      <td>0.419718</td>\n",
       "      <td>-4.168532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004684</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.155197</td>\n",
       "      <td>-1.134601</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.214048</td>\n",
       "      <td>-0.218007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.242751</td>\n",
       "      <td>-0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>404</td>\n",
       "      <td>med</td>\n",
       "      <td>-0.198599</td>\n",
       "      <td>-0.239107</td>\n",
       "      <td>-0.214293</td>\n",
       "      <td>-0.226611</td>\n",
       "      <td>-0.223416</td>\n",
       "      <td>-0.214293</td>\n",
       "      <td>0.859210</td>\n",
       "      <td>0.209883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037781</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>0.277871</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.199968</td>\n",
       "      <td>-0.229447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.238214</td>\n",
       "      <td>-0.230084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>679</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.183238</td>\n",
       "      <td>-0.226061</td>\n",
       "      <td>-0.201066</td>\n",
       "      <td>-0.218583</td>\n",
       "      <td>-0.218760</td>\n",
       "      <td>-0.201066</td>\n",
       "      <td>-0.199565</td>\n",
       "      <td>0.208781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037780</td>\n",
       "      <td>-0.047253</td>\n",
       "      <td>0.537611</td>\n",
       "      <td>-1.169235</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.196448</td>\n",
       "      <td>-0.231728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253378</td>\n",
       "      <td>-0.230842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>967</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.183756</td>\n",
       "      <td>-0.224326</td>\n",
       "      <td>-0.199780</td>\n",
       "      <td>-0.213349</td>\n",
       "      <td>-0.213875</td>\n",
       "      <td>-0.199780</td>\n",
       "      <td>-0.359380</td>\n",
       "      <td>0.205124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037780</td>\n",
       "      <td>-0.047284</td>\n",
       "      <td>0.104606</td>\n",
       "      <td>-1.125806</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.211936</td>\n",
       "      <td>-0.220567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.249421</td>\n",
       "      <td>-0.223404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>779</td>\n",
       "      <td>451</td>\n",
       "      <td>med</td>\n",
       "      <td>-0.198599</td>\n",
       "      <td>-0.218270</td>\n",
       "      <td>-0.203776</td>\n",
       "      <td>-0.144040</td>\n",
       "      <td>-0.175138</td>\n",
       "      <td>-0.203776</td>\n",
       "      <td>-0.449276</td>\n",
       "      <td>0.172585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037731</td>\n",
       "      <td>-0.044290</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>-0.082908</td>\n",
       "      <td>0.240790</td>\n",
       "      <td>0.216864</td>\n",
       "      <td>-0.206611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232781</td>\n",
       "      <td>-0.211051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>138</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.198634</td>\n",
       "      <td>-0.239096</td>\n",
       "      <td>-0.214293</td>\n",
       "      <td>-0.226580</td>\n",
       "      <td>-0.223333</td>\n",
       "      <td>-0.214293</td>\n",
       "      <td>0.589522</td>\n",
       "      <td>0.209836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037781</td>\n",
       "      <td>-0.048310</td>\n",
       "      <td>-0.241798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.207008</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253649</td>\n",
       "      <td>-0.230840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>537</td>\n",
       "      <td>med</td>\n",
       "      <td>-0.185277</td>\n",
       "      <td>-0.228114</td>\n",
       "      <td>-0.203077</td>\n",
       "      <td>-0.222786</td>\n",
       "      <td>-0.220120</td>\n",
       "      <td>-0.203077</td>\n",
       "      <td>-1.058571</td>\n",
       "      <td>0.209486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037781</td>\n",
       "      <td>-0.047428</td>\n",
       "      <td>-0.241798</td>\n",
       "      <td>-1.209707</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.228128</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253649</td>\n",
       "      <td>-0.230840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>697</td>\n",
       "      <td>low</td>\n",
       "      <td>3.320537</td>\n",
       "      <td>4.804306</td>\n",
       "      <td>4.876090</td>\n",
       "      <td>5.633489</td>\n",
       "      <td>5.604048</td>\n",
       "      <td>4.876090</td>\n",
       "      <td>0.469661</td>\n",
       "      <td>-4.071456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004643</td>\n",
       "      <td>-0.048187</td>\n",
       "      <td>-0.155197</td>\n",
       "      <td>-1.134963</td>\n",
       "      <td>-0.384974</td>\n",
       "      <td>0.228832</td>\n",
       "      <td>-0.218940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.241302</td>\n",
       "      <td>-0.222090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>783</td>\n",
       "      <td>718</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.198599</td>\n",
       "      <td>-0.239062</td>\n",
       "      <td>-0.214277</td>\n",
       "      <td>-0.226489</td>\n",
       "      <td>-0.223311</td>\n",
       "      <td>-0.214277</td>\n",
       "      <td>-1.328259</td>\n",
       "      <td>0.209740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037781</td>\n",
       "      <td>-0.048057</td>\n",
       "      <td>-0.241798</td>\n",
       "      <td>-0.100358</td>\n",
       "      <td>-0.297834</td>\n",
       "      <td>0.216160</td>\n",
       "      <td>-0.231940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253485</td>\n",
       "      <td>-0.230842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id classification       min       max      mean        sd  \\\n",
       "0         371            med -0.197098 -0.230893 -0.210207 -0.214613   \n",
       "1         693            low  3.324597  4.796719  4.874356  5.627270   \n",
       "2         404            med -0.198599 -0.239107 -0.214293 -0.226611   \n",
       "3         679            low -0.183238 -0.226061 -0.201066 -0.218583   \n",
       "4         967            low -0.183756 -0.224326 -0.199780 -0.213349   \n",
       "..        ...            ...       ...       ...       ...       ...   \n",
       "779       451            med -0.198599 -0.218270 -0.203776 -0.144040   \n",
       "780       138           high -0.198634 -0.239096 -0.214293 -0.226580   \n",
       "781       537            med -0.185277 -0.228114 -0.203077 -0.222786   \n",
       "782       697            low  3.320537  4.804306  4.876090  5.633489   \n",
       "783       718           high -0.198599 -0.239062 -0.214277 -0.226489   \n",
       "\n",
       "        range       sum  duplicates  mra_D1_min  ...  var_sill  var_range  \\\n",
       "0   -0.206882 -0.210207   -1.198409    0.188957  ... -0.037780  -0.047950   \n",
       "1    5.579711  4.874356    0.419718   -4.168532  ... -0.004684  -0.048187   \n",
       "2   -0.223416 -0.214293    0.859210    0.209883  ... -0.037781  -0.048127   \n",
       "3   -0.218760 -0.201066   -0.199565    0.208781  ... -0.037780  -0.047253   \n",
       "4   -0.213875 -0.199780   -0.359380    0.205124  ... -0.037780  -0.047284   \n",
       "..        ...       ...         ...         ...  ...       ...        ...   \n",
       "779 -0.175138 -0.203776   -0.449276    0.172585  ... -0.037731  -0.044290   \n",
       "780 -0.223333 -0.214293    0.589522    0.209836  ... -0.037781  -0.048310   \n",
       "781 -0.220120 -0.203077   -1.058571    0.209486  ... -0.037781  -0.047428   \n",
       "782  5.604048  4.876090    0.469661   -4.071456  ... -0.004643  -0.048187   \n",
       "783 -0.223311 -0.214277   -1.328259    0.209740  ... -0.037781  -0.048057   \n",
       "\n",
       "     var_kappa         g     zeros  num_peaks  gradient_max  gradient_min  \\\n",
       "0    -0.761404 -0.830924 -0.384974   0.228128     -0.231914           0.0   \n",
       "1    -0.155197 -1.134601 -0.384974   0.214048     -0.218007           0.0   \n",
       "2     0.018005  0.277871 -0.384974   0.199968     -0.229447           0.0   \n",
       "3     0.537611 -1.169235 -0.384974   0.196448     -0.231728           0.0   \n",
       "4     0.104606 -1.125806 -0.384974   0.211936     -0.220567           0.0   \n",
       "..         ...       ...       ...        ...           ...           ...   \n",
       "779   0.018005 -0.082908  0.240790   0.216864     -0.206611           0.0   \n",
       "780  -0.241798       NaN -0.384974   0.207008     -0.231914           0.0   \n",
       "781  -0.241798 -1.209707 -0.384974   0.228128     -0.231914           0.0   \n",
       "782  -0.155197 -1.134963 -0.384974   0.228832     -0.218940           0.0   \n",
       "783  -0.241798 -0.100358 -0.297834   0.216160     -0.231940           0.0   \n",
       "\n",
       "     gradient_mean  gradient_stdev  \n",
       "0        -0.253649       -0.230840  \n",
       "1        -0.242751       -0.221400  \n",
       "2        -0.238214       -0.230084  \n",
       "3        -0.253378       -0.230842  \n",
       "4        -0.249421       -0.223404  \n",
       "..             ...             ...  \n",
       "779      -0.232781       -0.211051  \n",
       "780      -0.253649       -0.230840  \n",
       "781      -0.253649       -0.230840  \n",
       "782      -0.241302       -0.222090  \n",
       "783      -0.253485       -0.230842  \n",
       "\n",
       "[784 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reads in training dataset (80% of given observations) and scales using StandardScaler\n",
    "df = pd.read_csv('train_X.csv')\n",
    "numeric_columns = ['min', 'max', 'mean', 'sd', 'range',\n",
    "       'sum','duplicates', 'mra_D1_min', 'mra_D1_max', 'mra_D1_mean', 'mra_D1_sd',\n",
    "       'mra_D1_range', 'mra_D1_zero', 'mra_D2_min', 'mra_D2_max',\n",
    "       'mra_D2_mean', 'mra_D2_sd', 'mra_D2_range', 'mra_D2_zero', 'mra_D3_min',\n",
    "       'mra_D3_max', 'mra_D3_mean', 'mra_D3_sd', 'mra_D3_range', 'mra_D3_zero',\n",
    "       'tri_min', 'tri_max', 'tri_mean', 'tri_sd', 'tri_range', 'var_sill',\n",
    "       'var_range', 'var_kappa', 'g', 'zeros', 'num_peaks', 'gradient_max', 'gradient_min', 'gradient_mean', 'gradient_stdev']\n",
    "df = pd.concat([\n",
    "    df[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "\n",
    "#Reads in validation dataset (15% of given observations) and scales\n",
    "df_val = pd.read_csv('validate_X.csv')\n",
    "df_val = pd.concat([\n",
    "    df_val[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df_val[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "\n",
    "#Reads in test dataset (5% of given observations) and scales\n",
    "df_test = pd.read_csv('test_X.csv')\n",
    "df_test = pd.concat([\n",
    "    df_test[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df_test[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum  duplicates  mra_D1_min  mra_D1_max  mra_D1_mean  mra_D1_sd  \\\n",
      "0   -0.210207   -1.198409    0.188957   -0.192009     0.131686  -0.195083   \n",
      "1    4.874356    0.419718   -4.168532    4.605365     3.051550   5.112639   \n",
      "2   -0.214293    0.859210    0.209883   -0.206535     0.064914  -0.217686   \n",
      "3   -0.201066   -0.199565    0.208781   -0.205953     0.066189  -0.216723   \n",
      "4   -0.199780   -0.359380    0.205124   -0.204086     0.066553  -0.211674   \n",
      "..        ...         ...         ...         ...          ...        ...   \n",
      "779 -0.203776   -0.449276    0.172585   -0.183689     0.004913  -0.166652   \n",
      "780 -0.214293    0.589522    0.209836   -0.206490     0.064945  -0.217636   \n",
      "781 -0.203077   -1.058571    0.209486   -0.206224     0.066098  -0.217042   \n",
      "782  4.876090    0.469661   -4.071456    4.656394     0.891173   5.108709   \n",
      "783 -0.214277   -1.328259    0.209740   -0.206379     0.064736  -0.217553   \n",
      "\n",
      "     mra_D1_range  mra_D1_zero  mra_D2_min  mra_D2_max  ...    tri_sd  \\\n",
      "0       -0.192331    -0.270253    0.197450   -0.186559  ... -0.194749   \n",
      "1        4.450026    -0.270253   -5.805578    5.125077  ...  5.668977   \n",
      "2       -0.209856    -0.270253    0.210519   -0.208780  ... -0.209236   \n",
      "3       -0.209035    -0.270253    0.209530   -0.207544  ... -0.207708   \n",
      "4       -0.206349    -0.270253    0.205876   -0.204880  ... -0.203854   \n",
      "..            ...          ...         ...         ...  ...       ...   \n",
      "779     -0.180327     0.802840    0.179457   -0.173215  ... -0.173258   \n",
      "780     -0.209809    -0.270253    0.210477   -0.208738  ... -0.209182   \n",
      "781     -0.209503    -0.270253    0.210052   -0.208244  ... -0.208010   \n",
      "782      4.435087    -0.270253   -5.776658    5.078642  ...  5.668296   \n",
      "783     -0.209704    -0.250314    0.210431   -0.208658  ... -0.209141   \n",
      "\n",
      "     tri_range  var_sill  var_range  var_kappa         g     zeros  \\\n",
      "0    -0.194738 -0.037780  -0.047950  -0.761404 -0.830924 -0.384974   \n",
      "1     4.700873 -0.004684  -0.048187  -0.155197 -1.134601 -0.384974   \n",
      "2    -0.208799 -0.037781  -0.048127   0.018005  0.277871 -0.384974   \n",
      "3    -0.207711 -0.037780  -0.047253   0.537611 -1.169235 -0.384974   \n",
      "4    -0.203959 -0.037780  -0.047284   0.104606 -1.125806 -0.384974   \n",
      "..         ...       ...        ...        ...       ...       ...   \n",
      "779  -0.172656 -0.037731  -0.044290   0.018005 -0.082908  0.240790   \n",
      "780  -0.208731 -0.037781  -0.048310  -0.241798       NaN -0.384974   \n",
      "781  -0.207929 -0.037781  -0.047428  -0.241798 -1.209707 -0.384974   \n",
      "782   4.712187 -0.004643  -0.048187  -0.155197 -1.134963 -0.384974   \n",
      "783  -0.208685 -0.037781  -0.048057  -0.241798 -0.100358 -0.297834   \n",
      "\n",
      "     gradient_max  gradient_mean  gradient_stdev  \n",
      "0       -0.231914      -0.253649       -0.230840  \n",
      "1       -0.218007      -0.242751       -0.221400  \n",
      "2       -0.229447      -0.238214       -0.230084  \n",
      "3       -0.231728      -0.253378       -0.230842  \n",
      "4       -0.220567      -0.249421       -0.223404  \n",
      "..            ...            ...             ...  \n",
      "779     -0.206611      -0.232781       -0.211051  \n",
      "780     -0.231914      -0.253649       -0.230840  \n",
      "781     -0.231914      -0.253649       -0.230840  \n",
      "782     -0.218940      -0.241302       -0.222090  \n",
      "783     -0.231940      -0.253485       -0.230842  \n",
      "\n",
      "[784 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "#Performs manual feature selection by dropping some variables from each set\n",
    "dropped_columns = ['image_id','classification','min','max','range','sd','mean', 'num_peaks', 'gradient_min']\n",
    "\n",
    "#Creates X and y for training, testing, and validation sets. \n",
    "X_train = df.drop(dropped_columns,axis=1)\n",
    "y_train = df['classification']\n",
    "X_val = df_val.drop(dropped_columns,axis=1)\n",
    "y_val = df_val['classification']\n",
    "X_test = df_test.drop(dropped_columns,axis=1)\n",
    "y_test = df_test['classification']\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21020726 -1.19840925  0.18895698 ... -0.23191411 -0.25364939\n",
      "  -0.23083959]\n",
      " [ 4.87435644  0.41971843 -4.16853218 ... -0.21800687 -0.24275114\n",
      "  -0.22140042]\n",
      " [-0.21429262  0.8592099   0.20988337 ... -0.22944744 -0.23821381\n",
      "  -0.23008442]\n",
      " ...\n",
      " [-0.27265531  0.54652516  0.29378731 ...  2.95897954  4.06658327\n",
      "   2.96917273]\n",
      " [ 4.00320067  0.60835625  0.08492225 ... -0.27978756 -0.29846159\n",
      "  -0.28281103]\n",
      " [-0.27292817  1.48429671  0.29399811 ... -0.29143839 -0.30427139\n",
      "  -0.29083625]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elise Madonna\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2a77a8f94c1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#Performs a grid search over the given parameters using F1 score as a metric.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mclf_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"f1_weighted\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mclf_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Random Forest Score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Random Forest Params:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "#Creates an index list to be used so that gridsearchcv differentiates between existing training and validation sets\n",
    "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
    "ps = PredefinedSplit(test_fold = split_index)\n",
    "X = np.concatenate((X_train, X_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "print(X)\n",
    "\n",
    "############################ Random Forest Hyperparameter Search ############################################\n",
    "#Initializes a random forest model\n",
    "rf = RandomForestClassifier()\n",
    "#Creates lists of possible parameters to try for the random forest\n",
    "rf_params = {\n",
    " 'max_depth': [10, 50, 100],\n",
    " 'random_state':[0],\n",
    " 'n_estimators': [200, 1000, 2000]\n",
    "}\n",
    "\n",
    "#Performs a grid search over the given parameters using F1 score as a metric.\n",
    "clf_rf = GridSearchCV(estimator = rf, cv=ps,scoring = \"f1_weighted\", param_grid=rf_params)\n",
    "clf_rf.fit(X, y)\n",
    "print(\"Best Random Forest Score:\", clf_rf.best_score_)\n",
    "print(\"Best Random Forest Params:\", clf_rf.best_params_)\n",
    "\n",
    "#Displays the features in order of importance for the Random Forest model\n",
    "print(\"\\nRandom Forest Feature importances:\")\n",
    "zipped_lists = zip(clf_rf.feature_importances_, X_train.columns)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")\n",
    "\n",
    "############################ Logistic Regression Hyperparamter Search #######################################\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Initializes a logistic regression model\n",
    "lr = LogisticRegression()\n",
    "#Creates lists of possible parameters to try for the logistic regression\n",
    "lr_params = {\n",
    "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
    "    \"random_state\": [0],\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "#Perfoms grid search over the given parameters using F1 score as a metric\n",
    "clf_lr = GridSearchCV(estimator = lr, cv=ps,scoring = \"f1_weighted\", param_grid=lr_params)\n",
    "clf_lr.fit(X, y)\n",
    "print(\"Best Logistic Regression Score:\", clf_lr.best_score_)\n",
    "print(\"Best Logistic Regression Params:\", clf_lr.best_params_)\n",
    "\n",
    "############################ K Nearest Neighbors Hyperparamter Search #######################################\n",
    "#Initializes a KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "#Creates a list of n_neighbors parameter values to try\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [i for i in range(1,20,1)]\n",
    "}\n",
    "#Performs grid search over given parameters using F1 score as a metric\n",
    "clf_knn = GridSearchCV(estimator = knn, cv=ps, scoring = \"f1_weighted\", param_grid=knn_params)\n",
    "clf_knn.fit(X, y)\n",
    "print(\"Best KNN Classifier Score:\", clf_knn.best_score_)\n",
    "print(\"Best KNN Classifier Params:\", clf_knn.best_params_)\n",
    "\n",
    "############################ Support Vector Machine Hyperparamter Search #######################################\n",
    "#Initializes a SVM classifier model\n",
    "svm_mod = svm.SVC()\n",
    "#Creates a list of C parameters to try\n",
    "svm_params = {\n",
    "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "#Performs grid search over given list of C parameters\n",
    "clf_svm = GridSearchCV(estimator = svm_mod, cv=ps,scoring = \"f1_weighted\", param_grid=svm_params)\n",
    "clf_svm.fit(X, y)\n",
    "print(\"Best SVM Score:\", clf_svm.best_score_)\n",
    "print(\"Best SVM Params:\", clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses test set to assess final test error of tuned model\n",
    "print(f\"RF Test Accuracy: {round(clf_rf.score(X_test, y_test), 3)}\")\n",
    "print(f\"LR Test Accuracy: {round(clf_lr.score(X_test, y_test), 3)}\")\n",
    "print(f\"KNN Test Accuracy: {round(clf_knn.score(X_test, y_test), 3)}\")\n",
    "print(f\"SVM Test Accuracy: {round(clf_svm.score(X_test, y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints confusion a confusion matrix for each model\n",
    "print(confusion_matrix(y_test, clf_rf.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf_lr.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf_knn.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints percent of correct predictions for each model based on confusion matrices\n",
    "\n",
    "print(\"RF % Correct:\",(24+1+8)/(24+2+11+8+ 1+ 1+ 2))\n",
    "print(\"LR % Correct:\",(4+3+4)/(4+3+4+21+1+2+14))\n",
    "print(\"KNN % Correct:\",(17+2+16)/(17+2+16+2+7+1+3+1))\n",
    "print(\"SVM % Correct:\",(19+1+3)/(19+1+3+5+2+2+8+9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "  Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "     plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix(y_test, clf_rf.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
