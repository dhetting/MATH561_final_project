{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>range</th>\n",
       "      <th>sum</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>mra_D1_min</th>\n",
       "      <th>...</th>\n",
       "      <th>var_sill</th>\n",
       "      <th>var_range</th>\n",
       "      <th>var_kappa</th>\n",
       "      <th>g</th>\n",
       "      <th>zeros</th>\n",
       "      <th>num_peaks</th>\n",
       "      <th>gradient_max</th>\n",
       "      <th>gradient_min</th>\n",
       "      <th>gradient_mean</th>\n",
       "      <th>gradient_stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039307</td>\n",
       "      <td>-0.038403</td>\n",
       "      <td>-0.512350</td>\n",
       "      <td>1.518153</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>-0.261946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272151</td>\n",
       "      <td>-0.261337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039307</td>\n",
       "      <td>-0.038851</td>\n",
       "      <td>-0.426757</td>\n",
       "      <td>1.486238</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>-0.261946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272151</td>\n",
       "      <td>-0.261337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039307</td>\n",
       "      <td>-0.038993</td>\n",
       "      <td>-0.426757</td>\n",
       "      <td>1.488180</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>-0.261946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272151</td>\n",
       "      <td>-0.261337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039307</td>\n",
       "      <td>-0.039168</td>\n",
       "      <td>-0.769128</td>\n",
       "      <td>1.435602</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>-0.261946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272151</td>\n",
       "      <td>-0.261337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039307</td>\n",
       "      <td>-0.039173</td>\n",
       "      <td>-0.769128</td>\n",
       "      <td>1.480840</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.239040</td>\n",
       "      <td>-0.261946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272151</td>\n",
       "      <td>-0.261337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>706</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223042</td>\n",
       "      <td>-0.260971</td>\n",
       "      <td>-0.237608</td>\n",
       "      <td>-0.232459</td>\n",
       "      <td>-0.233882</td>\n",
       "      <td>-0.237608</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.226484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.038192</td>\n",
       "      <td>0.086798</td>\n",
       "      <td>-1.432578</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.213364</td>\n",
       "      <td>-0.251005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.264181</td>\n",
       "      <td>-0.254032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>707</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223121</td>\n",
       "      <td>-0.260998</td>\n",
       "      <td>-0.237614</td>\n",
       "      <td>-0.232451</td>\n",
       "      <td>-0.233808</td>\n",
       "      <td>-0.237614</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.225263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.038233</td>\n",
       "      <td>0.086798</td>\n",
       "      <td>-1.432506</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.213364</td>\n",
       "      <td>-0.251275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.264205</td>\n",
       "      <td>-0.254255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>708</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223179</td>\n",
       "      <td>-0.261061</td>\n",
       "      <td>-0.237629</td>\n",
       "      <td>-0.232542</td>\n",
       "      <td>-0.233857</td>\n",
       "      <td>-0.237629</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.225791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.038395</td>\n",
       "      <td>0.172391</td>\n",
       "      <td>-1.433405</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>-0.251209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.264192</td>\n",
       "      <td>-0.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>709</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223129</td>\n",
       "      <td>-0.260764</td>\n",
       "      <td>-0.237616</td>\n",
       "      <td>-0.232654</td>\n",
       "      <td>-0.233239</td>\n",
       "      <td>-0.237616</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.038355</td>\n",
       "      <td>0.172391</td>\n",
       "      <td>-1.434569</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.211282</td>\n",
       "      <td>-0.251398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.264431</td>\n",
       "      <td>-0.254352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>710</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223086</td>\n",
       "      <td>-0.260959</td>\n",
       "      <td>-0.237603</td>\n",
       "      <td>-0.232529</td>\n",
       "      <td>-0.233777</td>\n",
       "      <td>-0.237603</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.038316</td>\n",
       "      <td>0.172391</td>\n",
       "      <td>-1.433459</td>\n",
       "      <td>-0.410836</td>\n",
       "      <td>0.209894</td>\n",
       "      <td>-0.251394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.264545</td>\n",
       "      <td>-0.254347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id classification       min       max      mean        sd  \\\n",
       "0           1           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "1           2           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "2           3           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "3           4           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "4           5           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "..        ...            ...       ...       ...       ...       ...   \n",
       "705       706            low -0.223042 -0.260971 -0.237608 -0.232459   \n",
       "706       707            low -0.223121 -0.260998 -0.237614 -0.232451   \n",
       "707       708            low -0.223179 -0.261061 -0.237629 -0.232542   \n",
       "708       709            low -0.223129 -0.260764 -0.237616 -0.232654   \n",
       "709       710            low -0.223086 -0.260959 -0.237603 -0.232529   \n",
       "\n",
       "        range       sum  duplicates  mra_D1_min  ...  var_sill  var_range  \\\n",
       "0   -0.242619 -0.249757   -0.092816    0.231935  ... -0.039307  -0.038403   \n",
       "1   -0.242619 -0.249757   -0.092816    0.231935  ... -0.039307  -0.038851   \n",
       "2   -0.242619 -0.249757   -0.092816    0.231935  ... -0.039307  -0.038993   \n",
       "3   -0.242619 -0.249757   -0.092816    0.231935  ... -0.039307  -0.039168   \n",
       "4   -0.242619 -0.249757   -0.092816    0.231935  ... -0.039307  -0.039173   \n",
       "..        ...       ...         ...         ...  ...       ...        ...   \n",
       "705 -0.233882 -0.237608   -0.092816    0.226484  ... -0.039306  -0.038192   \n",
       "706 -0.233808 -0.237614   -0.092816    0.225263  ... -0.039306  -0.038233   \n",
       "707 -0.233857 -0.237629   -0.092816    0.225791  ... -0.039306  -0.038395   \n",
       "708 -0.233239 -0.237616   -0.092816    0.225878  ... -0.039306  -0.038355   \n",
       "709 -0.233777 -0.237603   -0.092816    0.226305  ... -0.039306  -0.038316   \n",
       "\n",
       "     var_kappa         g     zeros  num_peaks  gradient_max  gradient_min  \\\n",
       "0    -0.512350  1.518153 -0.410836   0.239040     -0.261946           0.0   \n",
       "1    -0.426757  1.486238 -0.410836   0.239040     -0.261946           0.0   \n",
       "2    -0.426757  1.488180 -0.410836   0.239040     -0.261946           0.0   \n",
       "3    -0.769128  1.435602 -0.410836   0.239040     -0.261946           0.0   \n",
       "4    -0.769128  1.480840 -0.410836   0.239040     -0.261946           0.0   \n",
       "..         ...       ...       ...        ...           ...           ...   \n",
       "705   0.086798 -1.432578 -0.410836   0.213364     -0.251005           0.0   \n",
       "706   0.086798 -1.432506 -0.410836   0.213364     -0.251275           0.0   \n",
       "707   0.172391 -1.433405 -0.410836   0.212670     -0.251209           0.0   \n",
       "708   0.172391 -1.434569 -0.410836   0.211282     -0.251398           0.0   \n",
       "709   0.172391 -1.433459 -0.410836   0.209894     -0.251394           0.0   \n",
       "\n",
       "     gradient_mean  gradient_stdev  \n",
       "0        -0.272151       -0.261337  \n",
       "1        -0.272151       -0.261337  \n",
       "2        -0.272151       -0.261337  \n",
       "3        -0.272151       -0.261337  \n",
       "4        -0.272151       -0.261337  \n",
       "..             ...             ...  \n",
       "705      -0.264181       -0.254032  \n",
       "706      -0.264205       -0.254255  \n",
       "707      -0.264192       -0.254200  \n",
       "708      -0.264431       -0.254352  \n",
       "709      -0.264545       -0.254347  \n",
       "\n",
       "[710 rows x 42 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reads in training dataset (80% of given observations) and scales using StandardScaler\n",
    "df = pd.read_csv('train_X.csv')\n",
    "numeric_columns = ['min', 'max', 'mean', 'sd', 'range',\n",
    "       'sum','duplicates', 'mra_D1_min', 'mra_D1_max', 'mra_D1_mean', 'mra_D1_sd',\n",
    "       'mra_D1_range', 'mra_D1_zero', 'mra_D2_min', 'mra_D2_max',\n",
    "       'mra_D2_mean', 'mra_D2_sd', 'mra_D2_range', 'mra_D2_zero', 'mra_D3_min',\n",
    "       'mra_D3_max', 'mra_D3_mean', 'mra_D3_sd', 'mra_D3_range', 'mra_D3_zero',\n",
    "       'tri_min', 'tri_max', 'tri_mean', 'tri_sd', 'tri_range', 'var_sill',\n",
    "       'var_range', 'var_kappa', 'g', 'zeros', 'num_peaks', 'gradient_max', 'gradient_min', 'gradient_mean', 'gradient_stdev']\n",
    "df = pd.concat([\n",
    "    df[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "\n",
    "#Reads in validation dataset (15% of given observations) and scales\n",
    "df_val = pd.read_csv('validate_X.csv')\n",
    "df_val = pd.concat([\n",
    "    df_val[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df_val[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "\n",
    "#Reads in test dataset (5% of given observations) and scales\n",
    "df_test = pd.read_csv('test_X.csv')\n",
    "df_test = pd.concat([\n",
    "    df_test[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df_test[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs manual feature selection by dropping some variables from each set\n",
    "dropped_columns = ['image_id','classification','min','max','range','sd','mean', 'mra_D1_zero', 'mra_D2_mean', 'mra_D2_sd', 'mra_D2_range', 'mra_D3_max', 'mra_D3_mean', 'mra_D3_sd',  'mra_D3_range', 'mra_D3_zero',   'gradient_min']\n",
    "\n",
    "#Creates X and y for training, testing, and validation sets. \n",
    "X_train = df.drop(dropped_columns,axis=1)\n",
    "y_train = df['classification']\n",
    "X_val = df_val.drop(dropped_columns,axis=1)\n",
    "y_val = df_val['classification']\n",
    "X_test = df_test.drop(dropped_columns,axis=1)\n",
    "y_test = df_test['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Score: 0.5991921864044831\n",
      "Best Random Forest Params: {'max_depth': 10, 'n_estimators': 2000, 'random_state': 0}\n",
      "\n",
      "Random Forest Feature importances:\n",
      "0.24 g\n",
      "0.15 var_range\n",
      "0.07 sum\n",
      "0.07 gradient_stdev\n",
      "0.07 gradient_max\n",
      "0.06 gradient_mean\n",
      "0.03 mra_D3_min\n",
      "0.03 zeros\n",
      "0.02 mra_D1_max\n",
      "0.02 num_peaks\n",
      "0.02 var_kappa\n",
      "0.02 mra_D2_max\n",
      "0.02 tri_mean\n",
      "0.02 var_sill\n",
      "0.02 tri_range\n",
      "0.02 tri_max\n",
      "0.02 tri_min\n",
      "0.02 mra_D2_min\n",
      "0.02 tri_sd\n",
      "0.02 mra_D1_range\n",
      "0.02 mra_D1_sd\n",
      "0.01 mra_D1_min\n",
      "0.01 mra_D2_zero\n",
      "0.01 mra_D1_mean\n",
      "0.0 duplicates\n",
      "Best Logistic Regression Score: 0.6883000178734707\n",
      "Best Logistic Regression Params: {'C': 1, 'max_iter': 1000, 'random_state': 0}\n",
      "Best KNN Classifier Score: 0.6117043450376785\n",
      "Best KNN Classifier Params: {'n_neighbors': 14}\n",
      "Best SVM Score: 0.6827126861706063\n",
      "Best SVM Params: {'C': 100.0, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "#Creates an index list to be used so that gridsearchcv differentiates between existing training and validation sets\n",
    "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
    "ps = PredefinedSplit(test_fold = split_index)\n",
    "X = np.concatenate((X_train, X_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "############################ Random Forest Hyperparameter Search ############################################\n",
    "#Initializes a random forest model\n",
    "rf = RandomForestClassifier()\n",
    "#Creates lists of possible parameters to try for the random forest\n",
    "rf_params = {\n",
    " 'max_depth': [10, 50, 100],\n",
    " 'random_state':[0],\n",
    " 'n_estimators': [200, 1000, 2000]\n",
    "}\n",
    "\n",
    "#Performs a grid search over the given parameters using F1 score as a metric.\n",
    "clf_rf = GridSearchCV(estimator = rf, cv=ps,scoring = \"f1_weighted\", param_grid=rf_params)\n",
    "clf_rf.fit(X, y)\n",
    "print(\"Best Random Forest Score:\", clf_rf.best_score_)\n",
    "print(\"Best Random Forest Params:\", clf_rf.best_params_)\n",
    "\n",
    "#Displays the features in order of importance for the Random Forest model\n",
    "print(\"\\nRandom Forest Feature importances:\")\n",
    "#Creates a new RF model that is not a gridsearchcv object so that feature importances can be calculated\n",
    "clf_rf_features = RandomForestClassifier(max_depth = clf_rf.best_params_[\"max_depth\"], n_estimators = clf_rf.best_params_[\"n_estimators\"], random_state = 0)\n",
    "clf_rf_features.fit(X,y)\n",
    "#Calculates and displays feature importances\n",
    "zipped_lists = zip(clf_rf_features.feature_importances_, X_train.columns)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")\n",
    "\n",
    "############################ Logistic Regression Hyperparamter Search #######################################\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Initializes a logistic regression model\n",
    "lr = LogisticRegression()\n",
    "#Creates lists of possible parameters to try for the logistic regression\n",
    "lr_params = {\n",
    "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
    "    \"random_state\": [0],\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "#Perfoms grid search over the given parameters using F1 score as a metric\n",
    "clf_lr = GridSearchCV(estimator = lr, cv=ps,scoring = \"f1_weighted\", param_grid=lr_params)\n",
    "clf_lr.fit(X, y)\n",
    "print(\"Best Logistic Regression Score:\", clf_lr.best_score_)\n",
    "print(\"Best Logistic Regression Params:\", clf_lr.best_params_)\n",
    "\n",
    "############################ K Nearest Neighbors Hyperparamter Search #######################################\n",
    "#Initializes a KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "#Creates a list of n_neighbors parameter values to try\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [i for i in range(1,20,1)]\n",
    "}\n",
    "#Performs grid search over given parameters using F1 score as a metric\n",
    "clf_knn = GridSearchCV(estimator = knn, cv=ps, scoring = \"f1_weighted\", param_grid=knn_params)\n",
    "clf_knn.fit(X, y)\n",
    "print(\"Best KNN Classifier Score:\", clf_knn.best_score_)\n",
    "print(\"Best KNN Classifier Params:\", clf_knn.best_params_)\n",
    "\n",
    "############################ Support Vector Machine Hyperparamter Search #######################################\n",
    "#Initializes a SVM classifier model\n",
    "svm_mod = svm.SVC()\n",
    "#Creates a list of C parameters to try\n",
    "svm_params = {\n",
    "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "#Performs grid search over given list of C parameters\n",
    "clf_svm = GridSearchCV(estimator = svm_mod, cv=ps,scoring = \"f1_weighted\", param_grid=svm_params)\n",
    "clf_svm.fit(X, y)\n",
    "print(\"Best SVM Score:\", clf_svm.best_score_)\n",
    "print(\"Best SVM Params:\", clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Test Accuracy: 0.868\n",
      "LR Test Accuracy: 0.683\n",
      "KNN Test Accuracy: 0.735\n",
      "SVM Test Accuracy: 0.877\n"
     ]
    }
   ],
   "source": [
    "#Uses test set to assess final test error of tuned model\n",
    "print(f\"RF Test Accuracy: {round(clf_rf.score(X_test, y_test), 3)}\")\n",
    "print(f\"LR Test Accuracy: {round(clf_lr.score(X_test, y_test), 3)}\")\n",
    "print(f\"KNN Test Accuracy: {round(clf_knn.score(X_test, y_test), 3)}\")\n",
    "print(f\"SVM Test Accuracy: {round(clf_svm.score(X_test, y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  0  1]\n",
      " [ 0 20  0]\n",
      " [ 8  8 30]]\n",
      "[[69  0  0]\n",
      " [ 0  3 17]\n",
      " [14  5 27]]\n",
      "[[55  0 14]\n",
      " [ 0  7 13]\n",
      " [19  9 18]]\n",
      "[[69  0  0]\n",
      " [ 0 17  3]\n",
      " [10 12 24]]\n"
     ]
    }
   ],
   "source": [
    "#Prints confusion a confusion matrix for each model\n",
    "print(confusion_matrix(y_test, clf_rf.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf_lr.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf_knn.predict(X_test)))\n",
    "print(confusion_matrix(y_test, clf_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF % Correct: 0.673469387755102\n",
      "LR % Correct: 0.22448979591836735\n",
      "KNN % Correct: 0.7142857142857143\n",
      "SVM % Correct: 0.46938775510204084\n"
     ]
    }
   ],
   "source": [
    "#Prints percent of correct predictions for each model based on confusion matrices\n",
    "\n",
    "print(\"RF % Correct:\",(24+1+8)/(24+2+11+8+ 1+ 1+ 2))\n",
    "print(\"LR % Correct:\",(4+3+4)/(4+3+4+21+1+2+14))\n",
    "print(\"KNN % Correct:\",(17+2+16)/(17+2+16+2+7+1+3+1))\n",
    "print(\"SVM % Correct:\",(19+1+3)/(19+1+3+5+2+2+8+9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "  Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "     plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix(y_test, clf_rf.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
