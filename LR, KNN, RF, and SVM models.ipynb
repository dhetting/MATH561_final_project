{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b722d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e3faff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>range</th>\n",
       "      <th>sum</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>mra_D1_min</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SD</th>\n",
       "      <th>Left_mean</th>\n",
       "      <th>Left_SD</th>\n",
       "      <th>Left_median</th>\n",
       "      <th>Left_skew</th>\n",
       "      <th>Right_mean</th>\n",
       "      <th>Right_SD</th>\n",
       "      <th>Right_median</th>\n",
       "      <th>Right_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251054</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.244366</td>\n",
       "      <td>-0.248084</td>\n",
       "      <td>-0.242703</td>\n",
       "      <td>1.216154</td>\n",
       "      <td>-0.265452</td>\n",
       "      <td>-0.246725</td>\n",
       "      <td>-0.264706</td>\n",
       "      <td>-0.083643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540150</td>\n",
       "      <td>-0.244092</td>\n",
       "      <td>-0.244376</td>\n",
       "      <td>-0.248024</td>\n",
       "      <td>-0.242713</td>\n",
       "      <td>-0.563995</td>\n",
       "      <td>-0.265452</td>\n",
       "      <td>-0.246675</td>\n",
       "      <td>-0.264706</td>\n",
       "      <td>-0.097259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>-0.244102</td>\n",
       "      <td>-0.244365</td>\n",
       "      <td>-0.248026</td>\n",
       "      <td>-0.242703</td>\n",
       "      <td>0.131687</td>\n",
       "      <td>-0.265431</td>\n",
       "      <td>-0.246643</td>\n",
       "      <td>-0.264687</td>\n",
       "      <td>0.624789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>-0.244103</td>\n",
       "      <td>-0.244365</td>\n",
       "      <td>-0.248027</td>\n",
       "      <td>-0.242703</td>\n",
       "      <td>0.115957</td>\n",
       "      <td>-0.265431</td>\n",
       "      <td>-0.246624</td>\n",
       "      <td>-0.264686</td>\n",
       "      <td>0.750865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>high</td>\n",
       "      <td>-0.235309</td>\n",
       "      <td>-0.273585</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.244137</td>\n",
       "      <td>-0.242619</td>\n",
       "      <td>-0.249757</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.231935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>-0.244118</td>\n",
       "      <td>-0.244366</td>\n",
       "      <td>-0.248054</td>\n",
       "      <td>-0.242703</td>\n",
       "      <td>0.432565</td>\n",
       "      <td>-0.265437</td>\n",
       "      <td>-0.246665</td>\n",
       "      <td>-0.264692</td>\n",
       "      <td>1.226158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>706</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223042</td>\n",
       "      <td>-0.260971</td>\n",
       "      <td>-0.237608</td>\n",
       "      <td>-0.232459</td>\n",
       "      <td>-0.233882</td>\n",
       "      <td>-0.237608</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.226484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394149</td>\n",
       "      <td>-0.236994</td>\n",
       "      <td>-0.232201</td>\n",
       "      <td>-0.243047</td>\n",
       "      <td>-0.230574</td>\n",
       "      <td>-0.376331</td>\n",
       "      <td>-0.254196</td>\n",
       "      <td>-0.240827</td>\n",
       "      <td>-0.253426</td>\n",
       "      <td>-1.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>707</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223121</td>\n",
       "      <td>-0.260998</td>\n",
       "      <td>-0.237614</td>\n",
       "      <td>-0.232451</td>\n",
       "      <td>-0.233808</td>\n",
       "      <td>-0.237614</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.225263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439211</td>\n",
       "      <td>-0.233194</td>\n",
       "      <td>-0.230814</td>\n",
       "      <td>-0.234543</td>\n",
       "      <td>-0.228901</td>\n",
       "      <td>-0.563781</td>\n",
       "      <td>-0.252635</td>\n",
       "      <td>-0.237841</td>\n",
       "      <td>-0.251966</td>\n",
       "      <td>0.379353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>708</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223179</td>\n",
       "      <td>-0.261061</td>\n",
       "      <td>-0.237629</td>\n",
       "      <td>-0.232542</td>\n",
       "      <td>-0.233857</td>\n",
       "      <td>-0.237629</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.225791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481930</td>\n",
       "      <td>-0.230728</td>\n",
       "      <td>-0.232099</td>\n",
       "      <td>-0.236020</td>\n",
       "      <td>-0.230345</td>\n",
       "      <td>-0.530996</td>\n",
       "      <td>-0.253052</td>\n",
       "      <td>-0.234450</td>\n",
       "      <td>-0.252242</td>\n",
       "      <td>-0.837254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223129</td>\n",
       "      <td>-0.260764</td>\n",
       "      <td>-0.237616</td>\n",
       "      <td>-0.232654</td>\n",
       "      <td>-0.233239</td>\n",
       "      <td>-0.237616</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673420</td>\n",
       "      <td>-0.243791</td>\n",
       "      <td>-0.244133</td>\n",
       "      <td>-0.247739</td>\n",
       "      <td>-0.242471</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>-0.265168</td>\n",
       "      <td>-0.246415</td>\n",
       "      <td>-0.264420</td>\n",
       "      <td>-2.278212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>low</td>\n",
       "      <td>-0.223086</td>\n",
       "      <td>-0.260959</td>\n",
       "      <td>-0.237603</td>\n",
       "      <td>-0.232529</td>\n",
       "      <td>-0.233777</td>\n",
       "      <td>-0.237603</td>\n",
       "      <td>-0.092816</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674940</td>\n",
       "      <td>-0.243790</td>\n",
       "      <td>-0.244140</td>\n",
       "      <td>-0.247743</td>\n",
       "      <td>-0.242479</td>\n",
       "      <td>-0.451878</td>\n",
       "      <td>-0.265174</td>\n",
       "      <td>-0.246425</td>\n",
       "      <td>-0.264425</td>\n",
       "      <td>-2.343587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id classification       min       max      mean        sd  \\\n",
       "0           1           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "1           2           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "2           3           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "3           4           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "4           5           high -0.235309 -0.273585 -0.249757 -0.244137   \n",
       "..        ...            ...       ...       ...       ...       ...   \n",
       "705       706            low -0.223042 -0.260971 -0.237608 -0.232459   \n",
       "706       707            low -0.223121 -0.260998 -0.237614 -0.232451   \n",
       "707       708            low -0.223179 -0.261061 -0.237629 -0.232542   \n",
       "708       709            low -0.223129 -0.260764 -0.237616 -0.232654   \n",
       "709       710            low -0.223086 -0.260959 -0.237603 -0.232529   \n",
       "\n",
       "        range       sum  duplicates  mra_D1_min  ...      Skew        SD  \\\n",
       "0   -0.242619 -0.249757   -0.092816    0.231935  ...  1.251054 -0.244137   \n",
       "1   -0.242619 -0.249757   -0.092816    0.231935  ... -0.540150 -0.244092   \n",
       "2   -0.242619 -0.249757   -0.092816    0.231935  ...  0.020468 -0.244102   \n",
       "3   -0.242619 -0.249757   -0.092816    0.231935  ...  0.021317 -0.244103   \n",
       "4   -0.242619 -0.249757   -0.092816    0.231935  ...  0.249423 -0.244118   \n",
       "..        ...       ...         ...         ...  ...       ...       ...   \n",
       "705 -0.233882 -0.237608   -0.092816    0.226484  ... -0.394149 -0.236994   \n",
       "706 -0.233808 -0.237614   -0.092816    0.225263  ... -0.439211 -0.233194   \n",
       "707 -0.233857 -0.237629   -0.092816    0.225791  ... -0.481930 -0.230728   \n",
       "708 -0.233239 -0.237616   -0.092816    0.225878  ... -0.673420 -0.243791   \n",
       "709 -0.233777 -0.237603   -0.092816    0.226305  ... -0.674940 -0.243790   \n",
       "\n",
       "     Left_mean   Left_SD  Left_median  Left_skew  Right_mean  Right_SD  \\\n",
       "0    -0.244366 -0.248084    -0.242703   1.216154   -0.265452 -0.246725   \n",
       "1    -0.244376 -0.248024    -0.242713  -0.563995   -0.265452 -0.246675   \n",
       "2    -0.244365 -0.248026    -0.242703   0.131687   -0.265431 -0.246643   \n",
       "3    -0.244365 -0.248027    -0.242703   0.115957   -0.265431 -0.246624   \n",
       "4    -0.244366 -0.248054    -0.242703   0.432565   -0.265437 -0.246665   \n",
       "..         ...       ...          ...        ...         ...       ...   \n",
       "705  -0.232201 -0.243047    -0.230574  -0.376331   -0.254196 -0.240827   \n",
       "706  -0.230814 -0.234543    -0.228901  -0.563781   -0.252635 -0.237841   \n",
       "707  -0.232099 -0.236020    -0.230345  -0.530996   -0.253052 -0.234450   \n",
       "708  -0.244133 -0.247739    -0.242471  -0.480372   -0.265168 -0.246415   \n",
       "709  -0.244140 -0.247743    -0.242479  -0.451878   -0.265174 -0.246425   \n",
       "\n",
       "     Right_median  Right_skew  \n",
       "0       -0.264706   -0.083643  \n",
       "1       -0.264706   -0.097259  \n",
       "2       -0.264687    0.624789  \n",
       "3       -0.264686    0.750865  \n",
       "4       -0.264692    1.226158  \n",
       "..            ...         ...  \n",
       "705     -0.253426   -1.004191  \n",
       "706     -0.251966    0.379353  \n",
       "707     -0.252242   -0.837254  \n",
       "708     -0.264420   -2.278212  \n",
       "709     -0.264425   -2.343587  \n",
       "\n",
       "[710 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reads in training dataset (80% of given observations) and scales using StandardScaler\n",
    "df = pd.read_csv('data/train_X.csv')\n",
    "numeric_columns = ['min', 'max', 'mean', 'sd', 'range',\n",
    "       'sum','duplicates', 'mra_D1_min', 'mra_D1_max', 'mra_D1_mean', 'mra_D1_sd',\n",
    "       'mra_D1_range', 'mra_D1_zero', 'mra_D2_min', 'mra_D2_max',\n",
    "       'mra_D2_mean', 'mra_D2_sd', 'mra_D2_range', 'mra_D2_zero', 'mra_D3_min',\n",
    "       'mra_D3_max', 'mra_D3_mean', 'mra_D3_sd', 'mra_D3_range', 'mra_D3_zero',\n",
    "       'tri_min', 'tri_max', 'tri_mean', 'tri_sd', 'tri_range', 'var_sill',\n",
    "       'var_range', 'var_kappa', 'g', 'zeros', 'num_peaks', 'gradient_max', 'gradient_min', 'gradient_mean', 'gradient_stdev',\n",
    "                  'Trimmed_mean', 'Median', 'Skew', 'SD',\n",
    "       'Left_mean', 'Left_SD', 'Left_median', 'Left_skew',\n",
    "       'Right_mean', 'Right_SD', 'Right_median', 'Right_skew']\n",
    "df = pd.concat([\n",
    "    df[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "\n",
    "#Reads in validation dataset (15% of given observations) and scales\n",
    "df_val = pd.read_csv('data/validate_X.csv')\n",
    "df_val = pd.concat([\n",
    "    df_val[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df_val[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "\n",
    "#Reads in test dataset (5% of given observations) and scales\n",
    "df_test = pd.read_csv('data/test_X.csv')\n",
    "df_test = pd.concat([\n",
    "    df_test[['image_id', 'classification']],\n",
    "    pd.DataFrame(StandardScaler().fit_transform(df_test[numeric_columns]), columns=numeric_columns)\n",
    "], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa74c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs manual feature selection by dropping some variables from each set\n",
    "dropped_columns = ['tri_min', 'tri_max', 'tri_mean', 'tri_sd', 'tri_range','zeros',\n",
    "       'var_sill', 'var_range', 'var_kappa','image_id','classification','sum','duplicates','min','max','range','sd','mean', 'mra_D1_zero', 'mra_D2_mean', 'mra_D2_sd', 'mra_D2_range', 'mra_D3_max', 'mra_D3_mean', 'mra_D3_sd',  'mra_D3_range', 'mra_D3_zero',   'gradient_min']\n",
    "\n",
    "#Creates X and y for training, testing, and validation sets. \n",
    "X_train = df.drop(dropped_columns,axis=1)\n",
    "y_train = df['classification']\n",
    "X_val = df_val.drop(dropped_columns,axis=1)\n",
    "y_val = df_val['classification']\n",
    "X_test = df_test.drop(dropped_columns,axis=1)\n",
    "y_test = df_test['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6ac27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creates an index list to be used so that gridsearchcv differentiates between existing training and validation sets\n",
    "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
    "ps = PredefinedSplit(test_fold = split_index)\n",
    "X = np.concatenate((X_train, X_val), axis=0)\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "############################ Random Forest Hyperparameter Search ############################################\n",
    "#Initializes a random forest model\n",
    "rf = RandomForestClassifier()\n",
    "#Creates lists of possible parameters to try for the random forest\n",
    "rf_params = {\n",
    " 'max_depth': [10, 50, 100],\n",
    " 'random_state':[0],\n",
    " 'n_estimators': [200, 1000, 2000]\n",
    "}\n",
    "\n",
    "#Performs a grid search over the given parameters using F1 score as a metric.\n",
    "clf_rf = GridSearchCV(estimator = rf, cv=ps,scoring = \"f1_weighted\", param_grid=rf_params)\n",
    "clf_rf.fit(X, y)\n",
    "print(\"Best Random Forest Score:\", clf_rf.best_score_)\n",
    "print(\"Best Random Forest Params:\", clf_rf.best_params_)\n",
    "\n",
    "#Displays the features in order of importance for the Random Forest model\n",
    "print(\"\\nRandom Forest Feature importances:\")\n",
    "#Creates a new RF model that is not a gridsearchcv object so that feature importances can be calculated\n",
    "clf_rf_features = RandomForestClassifier(max_depth = clf_rf.best_params_[\"max_depth\"], n_estimators = clf_rf.best_params_[\"n_estimators\"], random_state = 0)\n",
    "clf_rf_features.fit(X,y)\n",
    "#Calculates and displays feature importances\n",
    "zipped_lists = zip(clf_rf_features.feature_importances_, X_train.columns)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")\n",
    "\n",
    "############################ Logistic Regression Hyperparamter Search #######################################\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Initializes a logistic regression model\n",
    "lr = LogisticRegression()\n",
    "#Creates lists of possible parameters to try for the logistic regression\n",
    "lr_params = {\n",
    "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
    "    \"random_state\": [0],\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "#Perfoms grid search over the given parameters using F1 score as a metric\n",
    "clf_lr = GridSearchCV(estimator = lr, cv=ps,scoring = \"f1_weighted\", param_grid=lr_params)\n",
    "clf_lr.fit(X, y)\n",
    "print()\n",
    "print('Logistic Regression Coefficients: ')\n",
    "j = 1\n",
    "for i in clf_lr.best_estimator_.coef_:\n",
    "    print()\n",
    "    print('Class: ',j)\n",
    "    j+=1\n",
    "    zipped_lists = zip([abs(ele) for ele in i], X_train.columns)\n",
    "    sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "    for pair in sorted_pairs:\n",
    "        print(f\"{round(pair[0], 2)} {pair[1]}\")\n",
    "clf_lr.best_estimator_.coef_\n",
    "print(\"Best Logistic Regression Score:\", clf_lr.best_score_)\n",
    "print(\"Best Logistic Regression Params:\", clf_lr.best_params_)\n",
    "\n",
    "############################ K Nearest Neighbors Hyperparamter Search #######################################\n",
    "#Initializes a KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "#Creates a list of n_neighbors parameter values to try\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [i for i in range(1,20,1)]\n",
    "}\n",
    "#Performs grid search over given parameters using F1 score as a metric\n",
    "clf_knn = GridSearchCV(estimator = knn, cv=ps, scoring = \"f1_weighted\", param_grid=knn_params)\n",
    "clf_knn.fit(X, y)\n",
    "print(\"Best KNN Classifier Score:\", clf_knn.best_score_)\n",
    "print(\"Best KNN Classifier Params:\", clf_knn.best_params_)\n",
    "\n",
    "############################ Support Vector Machine Hyperparamter Search #######################################\n",
    "#Initializes a SVM classifier model\n",
    "svm_mod = svm.SVC()\n",
    "#Creates a list of C parameters to try\n",
    "svm_params = {\n",
    "    \"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e2, 1e3, 1e4],\n",
    "    \"random_state\": [0]\n",
    "}\n",
    "#Performs grid search over given list of C parameters\n",
    "clf_svm = GridSearchCV(estimator = svm_mod, cv=ps,scoring = \"f1_weighted\", param_grid=svm_params)\n",
    "clf_svm.fit(X, y)\n",
    "print(\"Best SVM Score:\", clf_svm.best_score_)\n",
    "print(\"Best SVM Params:\", clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses test set to assess final test error of tuned model\n",
    "print(f\"RF Test F1: {round(clf_rf.score(X_test, y_test), 3)}\")\n",
    "print(f\"LR Test F1: {round(clf_lr.score(X_test, y_test), 3)}\")\n",
    "print(f\"KNN Test F1: {round(clf_knn.score(X_test, y_test), 3)}\")\n",
    "print(f\"SVM Test F1: {round(clf_svm.score(X_test, y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea11f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints confusion a confusion matrix for each model\n",
    "cm_rf = confusion_matrix(y_test, clf_rf.predict(X_test))\n",
    "cm_lr = confusion_matrix(y_test, clf_lr.predict(X_test))\n",
    "cm_knn = confusion_matrix(y_test, clf_knn.predict(X_test))\n",
    "cm_svm = confusion_matrix(y_test, clf_svm.predict(X_test))\n",
    "\n",
    "print(cm_rf)\n",
    "print(cm_lr)\n",
    "print(cm_knn)\n",
    "print(cm_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bcf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints percent of correct predictions for each model based on confusion matrices\n",
    "cm_rf\n",
    "print(\"RF % Correct:\",np.trace(cm_rf) / np.sum(cm_rf).astype('float'))\n",
    "print(\"LR % Correct:\",np.trace(cm_lr) / np.sum(cm_lr).astype('float'))\n",
    "print(\"KNN % Correct:\",np.trace(cm_knn) / np.sum(cm_knn).astype('float'))\n",
    "print(\"SVM % Correct:\",np.trace(cm_svm) / np.sum(cm_svm).astype('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "  Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix(y_test, clf_rf.predict(X_test)),['high','medium','low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_selection(model, X_train, X_test, y_train, y_test):\n",
    "#     sfs = SequentialFeatureSelector\n",
    "#     rfe = RFE\n",
    "#     feature_selectors = [sfs]\n",
    "\n",
    "# #     models = [RandomForestClassifier(random_state=0)]\n",
    "\n",
    "#     best_accuracy = 0\n",
    "#     best_model = None\n",
    "#     best_selector = None\n",
    "# #     for model in models:\n",
    "#     for selector_method in feature_selectors:\n",
    "#         for n_features in range(1, X_train.shape[1]):\n",
    "            \n",
    "#             selector = selector_method(model, n_features_to_select=n_features)\n",
    "#             selector.fit(X_train, y_train)\n",
    "#             X_train_transformed = selector.transform(X_train)\n",
    "#             X_test_transformed = selector.transform(X_test)\n",
    "\n",
    "#             model.fit(X_train_transformed, y_train)\n",
    "#             test_accuracy = model.score(X_test_transformed, y_test)\n",
    "#             print(test_accuracy)\n",
    "\n",
    "#             if test_accuracy > best_accuracy:\n",
    "#                 best_accuracy = test_accuracy\n",
    "#                 best_model = model\n",
    "#                 best_selector = selector\n",
    "\n",
    "# #     with open(os.path.join(\"pkls\", \"best_model.pkl\"), 'wb') as handle:\n",
    "# #         pickle.dump(best_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# #     with open(os.path.join(\"pkls\", \"best_selector.pkl\"), 'wb') as handle:\n",
    "# #         pickle.dump(best_selector, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#     return best_model, best_selector, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection(rf,X_train, X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91edc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
