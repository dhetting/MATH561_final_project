{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reads in Datasets from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of the names of given datasets\n",
    "folders = [\"high_train\", \"med_train\", \"low_train\", \"high_validate\", \"med_validate\", \"low_validate\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an empty list that will hold data from each dataset\n",
    "sets_list = []\n",
    "#Iterates through dataset names to read in csvs from each dataset folder\n",
    "for dataset in folders:\n",
    "    #Creates an empty list to hold each image from each dataset\n",
    "    matrix_list = []\n",
    "    #Iterates through all csv files contained in each dataset's folder\n",
    "    for file in glob.glob(str(dataset) + '/' + '*.csv'):\n",
    "        #Reads in the csv\n",
    "        data = pd.read_csv(file, header = None)\n",
    "        #Makes the image data into a dataframe\n",
    "        df = pd.DataFrame(data)\n",
    "        #Drops the first row of the dataframe that contains labels\n",
    "        df = df.drop(labels = 0, axis = 0)\n",
    "        #Adds the image dataframe to the list of images\n",
    "        matrix_list.append(df)\n",
    "    #Adds the list of images from each dataset to a list containing all datasets\n",
    "    sets_list.append(matrix_list)\n",
    "\n",
    "#Sets list is a list of lists of dataframes\n",
    "#Sets list contains a list for each dataset which contains dataframes (each dataframe is one image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates Basic Statistical Properties for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates empty lists to contain stat values for all dataset\n",
    "all_mins = []\n",
    "all_maxs = []\n",
    "all_ranges = []\n",
    "all_means = []\n",
    "#Iterates through each dataset\n",
    "for dataset in sets_list:\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    ranges = []\n",
    "    means = []\n",
    "    #Iterates through each image from each dataset\n",
    "    for image in dataset:\n",
    "        #Calculates minimum, maximum, mean, and range for each dataset\n",
    "        mins.append(image.max())\n",
    "        maxs.append(image.min())\n",
    "        ranges.append(abs(image.max() - image.min()))\n",
    "        means.append(image.mean())\n",
    "    #Adds each value back into an overall list to consolidate all dataframes\n",
    "    all_mins.append(mins)\n",
    "    all_maxs.append(maxs)\n",
    "    all_ranges.append(ranges)\n",
    "    all_means.append(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates Number of Peaks in Each Image Using a Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elise Madonna\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1366: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "#Sets a percentile value to dictate what is defined as a peak (in this case, a peak is > 85 percentile)\n",
    "percentile = 85\n",
    "all_peaks = []\n",
    "for dataset in sets_list:\n",
    "    num_peaks = []\n",
    "    for image in dataset:\n",
    "        #Casts data from each image as a float to deal with type errors\n",
    "        image_np = image.astype(float)    \n",
    "        #Calculates a percentile value for the image based on percentile specified above\n",
    "        percentile_val = np.nanpercentile(image_np, percentile)\n",
    "        \n",
    "        #Creates an empty dataframe and then fills it with the calculated value of the image's percentile\n",
    "        percentile_df = pd.DataFrame(np.zeros([len(image_np), image_np.shape[1]]))\n",
    "        percentile_df = percentile_df.replace(0,percentile_val)\n",
    "    \n",
    "        #Find the difference between each value in the image and the percentile value for the image\n",
    "        diff = image_np - percentile_df\n",
    "        \n",
    "        #Counts the number of values in each image that are greater than the  percentile value\n",
    "        counter = 0\n",
    "        for rowIndex, row in diff.iterrows(): #iterate over rows\n",
    "            for columnIndex, value in row.items():\n",
    "                if value > 0:\n",
    "                    counter += 1\n",
    "\n",
    "        num_peaks.append(counter)\n",
    "    all_peaks.append(num_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates Gradient Behavior in Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list so that we can collect max, min, mean gradients for each dataset (as well as stdev of gradients)\n",
    "stats = [np.max, np.min, np.mean, np.std]\n",
    "op_gradients = []\n",
    "#Iterates through every operation we want to perform on the gradients\n",
    "for op in stats:\n",
    "    gradient = []\n",
    "    #Iterates through the 4 datasets\n",
    "    for dataset in sets_list:\n",
    "        image_grads = []\n",
    "         #Iterates through each image contained within each of the datasets\n",
    "        for image in dataset:\n",
    "            col = []\n",
    "            #Iterates through each column of pixel values within each image\n",
    "            for column in image:\n",
    "                #Converts to float to avoid type errors\n",
    "                column_np = image[column].astype(float)\n",
    "                #If the last column is reached, the gradient is written as zero to avoid comparing to out of range columns\n",
    "                if column == (image.shape[1] - 1):\n",
    "                    col.append(0)\n",
    "                #Else, if the column is not the last in the image\n",
    "                else:\n",
    "                     #compares the current column to the next column in the image\n",
    "                    next_col = image[column + 1].astype(float)\n",
    "                    #Takes gradients between the current and next columns (over both axes)\n",
    "                    # And performs one of the statistical operations for each column\n",
    "                    col.append(op(np.gradient([column_np, next_col])))\n",
    "            #Makes a list of gradient value for each image\n",
    "            image_grads.append(op(col))\n",
    "        #Adds the list of gradient values from each image in each dataset into a list that contains all datasets gradients\n",
    "        gradient.append(image)\n",
    "    #Adds all the dataset values to a list that contains one entry for each operation that was performed\n",
    "    op_gradients.append(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
