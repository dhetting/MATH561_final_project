{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "\n",
    "compression_levels = [\"low\", \"medium\", \"high\"]\n",
    "train_validate_list = [\"train\", \"validate\"]\n",
    "\n",
    "for level_i, compression_level in enumerate(compression_levels):\n",
    "    for train_validate in train_validate_list:\n",
    "        path = os.path.join(compression_level, train_validate)\n",
    "        for csv_name in os.listdir(path):\n",
    "            file_path = os.path.join(path, csv_name)\n",
    "            df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "            df = df.drop(df.columns[0], axis=1)\n",
    "            df = df.to_numpy()\n",
    "\n",
    "            # Uncomment this code to display the images\n",
    "            # df = df.T\n",
    "            # df = df[::-1]\n",
    "            # plt.imshow(df)\n",
    "            # plt.show()\n",
    "\n",
    "            # df_gray = cv2.cvtColor(df, cv2.COLOR_BGR2GRAY)\n",
    "            df_blur = cv2.GaussianBlur(df, (3,3), 0)\n",
    "\n",
    "            edges = cv2.Canny(image=np.uint8(df_blur), threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "\n",
    "            # edges = 255 - edges\n",
    "            edges[edges > 255] = 1\n",
    "\n",
    "            # plt.imshow(edges, cmap=plt.get_cmap('gray'))\n",
    "            # plt.show()\n",
    "\n",
    "            edges_count = np.sum(np.sum(edges))\n",
    "\n",
    "            df_flattened = df.flatten()\n",
    "\n",
    "            # Uncomment this code to display the histogram of the colors of the images\n",
    "            # plt.hist(df)\n",
    "            # plt.show()\n",
    "\n",
    "            mean = df_flattened.mean()\n",
    "            sd = df_flattened.std()\n",
    "            max_val = df_flattened.max()\n",
    "            min_val = df_flattened.min()\n",
    "            median = np.median(df_flattened)\n",
    "            trimmed_mean = stats.trim_mean(df_flattened, 0.2)\n",
    "            skew = stats.skew(df_flattened)\n",
    "            range_vals = max_val - min_val\n",
    "            avg_val = np.sum(df_flattened)\n",
    "\n",
    "            # Find if poisson\n",
    "            spread = max_val - min_val\n",
    "            if max_val - mean < 0.25 * spread:\n",
    "                is_poisson = True\n",
    "            else:\n",
    "                is_poisson = False\n",
    "\n",
    "            # Left and right stats\n",
    "            # Left\n",
    "            middle_val = (max_val - min_val) / 2 + min_val\n",
    "            left = df_flattened[df_flattened < middle_val]\n",
    "            left_mean = left.mean()\n",
    "            left_sd = left.std()\n",
    "            left_median = np.median(left)\n",
    "            left_skew = stats.skew(left)\n",
    "            # Right\n",
    "            right = df_flattened[df_flattened >= middle_val]\n",
    "            right_mean = right.mean()\n",
    "            right_sd = right.std()\n",
    "            right_median = np.median(right)\n",
    "            right_skew = stats.skew(right)\n",
    "\n",
    "            new_row = {\"Compression\": level_i,\n",
    "                       \"Train_validate\": train_validate,\n",
    "                       # Features\n",
    "                       \"Edges\": edges_count,\n",
    "                       \"Mean\": mean,\n",
    "                       \"Trimmed_mean\": trimmed_mean,\n",
    "                       \"Median\": median,\n",
    "                       \"Skew\": skew,\n",
    "                       \"Is_poisson\": is_poisson,\n",
    "                       \"SD\": sd,\n",
    "                       \"Max\": max_val,\n",
    "                       \"Min\": min_val,\n",
    "                       \"Range\": range_vals,\n",
    "                       \"Avg\": avg_val,\n",
    "                       \"Left_mean\": left_mean,\n",
    "                       \"Left_SD\": left_sd,\n",
    "                       \"Left_median\": left_median,\n",
    "                       \"Left_skew\": left_skew,\n",
    "                       \"Right_mean\": right_mean,\n",
    "                       \"Right_SD\": right_sd,\n",
    "                       \"Right_median\": right_median,\n",
    "                       \"Right_skew\": right_skew\n",
    "            }\n",
    "\n",
    "            data_df = data_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_df, train_validate):\n",
    "    X = data_df[(data_df[\"Train_validate\"] == train_validate)]\n",
    "    X = X.drop(columns=[\"Compression\", \"Train_validate\"])\n",
    "\n",
    "    y = data_df[(data_df[\"Train_validate\"] == train_validate)]\n",
    "    y = y[\"Compression\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.789\n",
      "\n",
      "Feature importances:\n",
      "0.21 Min\n",
      "0.11 Left_median\n",
      "0.09 Median\n",
      "0.08 Avg\n",
      "0.07 Right_skew\n",
      "0.06 Left_mean\n",
      "0.05 Skew\n",
      "0.05 Trimmed_mean\n",
      "0.04 Mean\n",
      "0.04 Right_median\n",
      "0.03 Right_mean\n",
      "0.03 Left_skew\n",
      "0.03 Max\n",
      "0.02 Edges\n",
      "0.02 SD\n",
      "0.02 Range\n",
      "0.02 Right_SD\n",
      "0.02 Left_SD\n",
      "0.0 Is_poisson\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean_data(data_df, \"train\")\n",
    "X_test, y_test = clean_data(data_df, \"validate\")\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy: {round(clf.score(X_train, y_train), 3)}\")\n",
    "print(f\"Test Accuracy: {round(clf.score(X_test, y_test), 3)}\")\n",
    "\n",
    "print(\"\\nFeature importances:\")\n",
    "zipped_lists = zip(clf.feature_importances_, X_train.columns)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train, X_test, y_train, y_test):\n",
    "    sfs = SequentialFeatureSelector\n",
    "    rfe = RFE\n",
    "    feature_selectors = [sfs, rfe]\n",
    "\n",
    "    models = [RandomForestClassifier]\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_selector = None\n",
    "    for model in models:\n",
    "        for selector_method in feature_selectors:\n",
    "            for n_features in range(1, X_train.shape[1]):\n",
    "                clf = model(random_state=0)\n",
    "                selector = selector_method(clf, n_features_to_select=n_features)\n",
    "                selector.fit(X_train, y_train)\n",
    "                X_train_transformed = selector.transform(X_train)\n",
    "                X_test_transformed = selector.transform(X_test)\n",
    "\n",
    "                clf.fit(X_train_transformed, y_train)\n",
    "                test_accuracy = clf.score(X_test_transformed, y_test)\n",
    "\n",
    "                if test_accuracy > best_accuracy:\n",
    "                    best_accuracy = test_accuracy\n",
    "                    best_model = clf\n",
    "                    best_selector = selector\n",
    "\n",
    "    with open(os.path.join(\"pkls\", \"best_model.pkl\"), 'wb') as handle:\n",
    "        pickle.dump(best_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(\"pkls\", \"best_selector.pkl\"), 'wb') as handle:\n",
    "        pickle.dump(best_selector, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return best_model, best_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(X_train, X_test, y_train, y_test, retrain=False):\n",
    "    if retrain:\n",
    "        return feature_selection(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    with open(os.path.join(\"pkls\", \"best_model.pkl\"), 'rb') as handle:\n",
    "        best_model = pickle.load(handle)\n",
    "\n",
    "    with open(os.path.join(\"pkls\", \"best_selector.pkl\"), 'rb') as handle:\n",
    "        best_selector = pickle.load(handle)\n",
    "\n",
    "    return best_model, best_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.995774647887324\n",
      "Test accuracy: 0.8555555555555555\n",
      "Feature importance:\n",
      "0.15 Left_median\n",
      "0.13 Median\n",
      "0.12 Avg\n",
      "0.11 Right_skew\n",
      "0.09 Mean\n",
      "0.09 Trimmed_mean\n",
      "0.07 Right_mean\n",
      "0.07 SD\n",
      "0.07 Left_SD\n",
      "0.06 Right_median\n",
      "0.05 Edges\n"
     ]
    }
   ],
   "source": [
    "best_model, best_selector = get_best_model(X_train, X_test, y_train, y_test, retrain=False)\n",
    "\n",
    "X_train_transformed = best_selector.transform(X_train)\n",
    "X_test_transformed = best_selector.transform(X_test)\n",
    "\n",
    "train_accuracy = best_model.score(X_train_transformed, y_train)\n",
    "test_accuracy = best_model.score(X_test_transformed, y_test)\n",
    "features = best_selector.get_feature_names_out()\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "\n",
    "print(\"Feature importance:\")\n",
    "zipped_lists = zip(best_model.feature_importances_, features)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features as csv\n",
    "high_train = data_df[(data_df[\"Compression\"] == 2.0) & (data_df[\"Train_validate\"] == \"train\")]\n",
    "med_train = data_df[(data_df[\"Compression\"] == 1.0) & (data_df[\"Train_validate\"] == \"train\")]\n",
    "low_train = data_df[(data_df[\"Compression\"] == 0.0) & (data_df[\"Train_validate\"] == \"train\")]\n",
    "high_validate = data_df[(data_df[\"Compression\"] == 2.0) & (data_df[\"Train_validate\"] == \"validate\")]\n",
    "med_validate = data_df[(data_df[\"Compression\"] == 1.0) & (data_df[\"Train_validate\"] == \"validate\")]\n",
    "low_validate = data_df[(data_df[\"Compression\"] == 0.0) & (data_df[\"Train_validate\"] == \"validate\")]\n",
    "\n",
    "combined_df_list = [low_validate, med_train, low_train, high_validate, med_validate, low_validate]\n",
    "combined_df = pd.concat(combined_df_list)\n",
    "\n",
    "combined_df['image_id'] = range(len(combined_df))\n",
    "\n",
    "combined_df.to_csv(\"descriptive_stats.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
