{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(s, ch):\n",
    "    return [i for i, ltr in enumerate(s) if ltr == ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "\n",
    "compression_levels = [\"low\", \"medium\", \"high\"]\n",
    "train_validate_list = [\"train\", \"validate\"]\n",
    "\n",
    "for level_i, compression_level in enumerate(compression_levels):\n",
    "    for train_validate in train_validate_list:\n",
    "        path = os.path.join(compression_level, train_validate)\n",
    "        for csv_name in os.listdir(path):\n",
    "            file_path = os.path.join(path, csv_name)\n",
    "            df = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "            df = df.drop(df.columns[0], axis=1)\n",
    "            df = df.to_numpy()\n",
    "\n",
    "            # Uncomment this code to display the images\n",
    "            # df = df.T\n",
    "            # df = df[::-1]\n",
    "            # plt.imshow(df)\n",
    "            # plt.show()\n",
    "\n",
    "            # df_gray = cv2.cvtColor(df, cv2.COLOR_BGR2GRAY)\n",
    "            df_blur = cv2.GaussianBlur(df, (3,3), 0)\n",
    "\n",
    "            edges = cv2.Canny(image=np.uint8(df_blur), threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "\n",
    "            # edges = 255 - edges\n",
    "            edges[edges > 255] = 1\n",
    "\n",
    "            # plt.imshow(edges, cmap=plt.get_cmap('gray'))\n",
    "            # plt.show()\n",
    "\n",
    "            edges_count = np.sum(np.sum(edges))\n",
    "\n",
    "            df_flattened = df.flatten()\n",
    "\n",
    "            # Uncomment this code to display the histogram of the colors of the images\n",
    "            # plt.hist(df)\n",
    "            # plt.show()\n",
    "\n",
    "            indexes = find(csv_name, \"_\")\n",
    "\n",
    "            sensor_type = csv_name[: indexes[-2]]\n",
    "            main_type = csv_name.split(\"_\")[-3]\n",
    "            period = csv_name.split(\"_\")[-2]\n",
    "            mean = df_flattened.mean()\n",
    "            sd = df_flattened.std()\n",
    "            max_val = df_flattened.max()\n",
    "            min_val = df_flattened.min()\n",
    "            median = np.median(df_flattened)\n",
    "            trimmed_mean = stats.trim_mean(df_flattened, 0.2)\n",
    "            skew = stats.skew(df_flattened)\n",
    "\n",
    "            # Find if poisson\n",
    "            spread = max_val - min_val\n",
    "            if max_val - mean < 0.25 * spread:\n",
    "                is_poisson = True\n",
    "            else:\n",
    "                is_poisson = False\n",
    "\n",
    "            # Left and right stats\n",
    "            # Left\n",
    "            middle_val = (max_val - min_val) / 2 + min_val\n",
    "            left = df_flattened[df_flattened < middle_val]\n",
    "            left_mean = left.mean()\n",
    "            left_sd = left.std()\n",
    "            left_median = np.median(left)\n",
    "            left_skew = stats.skew(left)\n",
    "            # Right\n",
    "            right = df_flattened[df_flattened >= middle_val]\n",
    "            right_mean = right.mean()\n",
    "            right_sd = right.std()\n",
    "            right_median = np.median(right)\n",
    "            right_skew = stats.skew(right)\n",
    "\n",
    "            new_row = {\"Compression\": level_i,\n",
    "                       \"Train_validate\": train_validate,\n",
    "                       \"Type\": sensor_type,\n",
    "                       \"Main_Type\": main_type,\n",
    "                       \"Period\": period,\n",
    "                       # Features\n",
    "                       \"Edges\": edges_count,\n",
    "                       \"Mean\": mean,\n",
    "                       \"Trimmed_mean\": trimmed_mean,\n",
    "                       \"Median\": median,\n",
    "                       \"Skew\": skew,\n",
    "                       \"Is_poisson\": is_poisson,\n",
    "                       \"SD\": sd,\n",
    "                       \"Max\": max_val,\n",
    "                       \"Min\": min_val,\n",
    "                       \"Left_mean\": left_mean,\n",
    "                       \"Left_SD\": left_sd,\n",
    "                       \"Left_median\": left_median,\n",
    "                       \"Left_skew\": left_skew,\n",
    "                       \"Right_mean\": right_mean,\n",
    "                       \"Right_SD\": right_sd,\n",
    "                       \"Right_median\": right_median,\n",
    "                       \"Right_skew\": right_skew\n",
    "            }\n",
    "\n",
    "            data_df = data_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_df, train_validate):\n",
    "    X = data_df[(data_df[\"Train_validate\"] == train_validate)]\n",
    "    X = X.drop(columns=[\"Compression\", \"Type\", \"Train_validate\", \"Main_Type\", \"Type\", \"Period\"])\n",
    "\n",
    "    y = data_df[(data_df[\"Train_validate\"] == train_validate)]\n",
    "    y = y[\"Compression\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.994\n",
      "Test Accuracy: 0.781\n",
      "\n",
      "Feature importances:\n",
      "0.21 Min\n",
      "0.1 Left_median\n",
      "0.09 Left_mean\n",
      "0.08 Median\n",
      "0.07 Right_skew\n",
      "0.06 Skew\n",
      "0.06 Trimmed_mean\n",
      "0.05 Mean\n",
      "0.05 Max\n",
      "0.04 Right_median\n",
      "0.04 SD\n",
      "0.04 Left_skew\n",
      "0.03 Right_mean\n",
      "0.03 Left_SD\n",
      "0.02 Right_SD\n",
      "0.02 Edges\n",
      "0.01 Is_poisson\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean_data(data_df, \"train\")\n",
    "X_test, y_test = clean_data(data_df, \"validate\")\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy: {round(clf.score(X_train, y_train), 3)}\")\n",
    "print(f\"Test Accuracy: {round(clf.score(X_test, y_test), 3)}\")\n",
    "\n",
    "print(\"\\nFeature importances:\")\n",
    "zipped_lists = zip(clf.feature_importances_, X_train.columns)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.8333333333333334\n",
      "Best features: ['Median' 'Min' 'Left_mean' 'Left_median' 'Right_skew']\n"
     ]
    }
   ],
   "source": [
    "def feature_selection(X_train, X_test, y_train, y_test):\n",
    "    sfs = SequentialFeatureSelector\n",
    "    rfe = RFE\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_features = None\n",
    "    for selector_method in [sfs, rfe]:\n",
    "        for n_features in range(1, X_train.shape[1]):\n",
    "            clf = RandomForestClassifier(random_state=0)\n",
    "            selector = selector_method(clf, n_features_to_select=n_features)\n",
    "            selector.fit(X_train, y_train)\n",
    "            X_train_transformed = selector.transform(X_train)\n",
    "            X_test_transformed = selector.transform(X_test)\n",
    "\n",
    "            clf.fit(X_train_transformed, y_train)\n",
    "            test_accuracy = clf.score(X_test_transformed, y_test)\n",
    "\n",
    "            if test_accuracy > best_accuracy:\n",
    "                best_accuracy = test_accuracy\n",
    "                best_model = clf\n",
    "                best_features = selector.get_feature_names_out()\n",
    "\n",
    "    print(f\"Best accuracy: {best_accuracy}\")\n",
    "    print(\"Best features:\", best_features)\n",
    "\n",
    "    # Uncomment to save model\n",
    "    # with open('best_model.pkl', 'wb') as handle:\n",
    "    #     pickle.dump(best_model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(X_train, X_test, y_train, y_test, retrain=False):\n",
    "    if retrain:\n",
    "        return feature_selection(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    with open('best_model.pkl', 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_best_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36 Min\n",
      "0.18 Left_median\n",
      "0.17 Median\n",
      "0.16 Left_mean\n",
      "0.14 Right_skew\n"
     ]
    }
   ],
   "source": [
    "# Copy and pasted column names. Didn't want to automate this\n",
    "features = ['Median', 'Min', 'Left_mean', 'Left_median', 'Right_skew']\n",
    "zipped_lists = zip(model.feature_importances_, features)\n",
    "sorted_pairs = sorted(zipped_lists, reverse=True)\n",
    "for pair in sorted_pairs:\n",
    "    print(f\"{round(pair[0], 2)} {pair[1]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
